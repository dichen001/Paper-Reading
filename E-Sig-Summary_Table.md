|             Year/Cite            | Name                                                                                     | Data                                                                                                                                                                                                                                                        | Method                                                                                                                                                                                                                                                                                                       | Results                                                                                                                                                                                                                                                                                               |                                                                                                        |
|:--------------------------------:|------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|
| 1999 /28                         | Subset of EMU (Bell Labs & UCB)                                                          | 1361 SBs from Lucent Tech.  CS @ Concordia U,                                                                                                                                                                                                               | geometrical & linguistic analysis  (weighted finite-state transducers WFST)                                                                                                                                                                                                                                  | Recall: 53%-->93% Precision: 90%                                                                                                                                                                                                                                                                      |                                                                                                        |
| 2004 /85                         | Learning to Extract Signature and Reply Lines from Email (CMU)                           | From 20 Newsgroups Dataset, manually annotated 617-message dataset.                                                                                                                                                                                         | Supervised Learning on annotated messages to develop component-level analysis.                                                                                                                                                                                                                               | Accuracy:>97% Sequential learners better than non-sequential. CRF best w/o. features.  CPerceptron(5,25) best w. features (best overall, accuracy 99.37%); CMM(SVM, 5) is a close second.                                                                                                             | Compared with Naive Byes, Maximum Entropy, SVM(best), VotedPreceptrop, AdaBoost.s                      |
| 2009 /16                         | Zebra (@csiro.au)                                                                        | 11881 annotated lines from 400 email drawn randomly from Enron.(zebra.thoughtlets.org)                                                                                                                                                                      | use SVM to segment email into 9 zone types based on graphic, orthographic and lexical cues.                                                                                                                                                                                                                  | accuracy of 87.01%, when the number of zones is abstracted to two or three zone classes, this increases to 93.60% and 91.53% respectively.                                                                                                                                                            |                                                                                                        |
| 2011 /07                         | Automatically Locating Salutation and Signature Blocks in Emails                         | Subset of the Enron corpus.  Randomly choose 2000 emails from 6065 emails of 20 users. Only 971 include SBs.                                                                                                                                                | Statistical and rules restricted method. 1. Remove quoted text.  2. Roughly decide, last K lines. 3. Using 3 simple rules to correct the result.                                                                                                                                                             | Average F1 value above 94%                                                                                                                                                                                                                                                                            | Do not use any features of text lines or email lay-out features.  Not comparable with the others work. |
| 2012 /1                          | InterpretingContact Details out of E-mail Signature Blocks                               | The service is available for user Gmail and Google Apps IMAP servers. Only French and English languages are fully covered but any ISO-latin signature can be analyzed                                                                                       | Context; Extraction of HTML Part from MIME format; Elimination of specific configurations; Language detection; Formatting Details in vCard; Standardizing Phone Numbers; Update the address books.                                                                                                           | Millions of emails were analyzed by the servers, specific rules were adopted: non-isolatin encoding or above-200kO emails, for instance, are not analyzed for the sake of robustness.                                                                                                                 |                                                                                                        |
| 2005* /144 Entity Identification | Extracting personal names from email: applying named entity recognition to informal text | Two email corpora were extracted from the CSpace email corpus (Kraut et al., 2004), which are from management courses. The next two collections of email were extracted from the Enron corpus (Klimt and Yang, 2004)                                        | Based on conditional random fields (CRE), they use special attributes of emalil text to improve the performance.(Basic, Dict., Email)                                                                                                                                                                        | F1: 87.9%-92.9 for Mgmt F1: 76.2%-76.9% for Enron.                                                                                                                                                                                                                                                    |                                                                                                        |
| 2006* /205 Email Visualization   | Visualizing email content: portraying relationships from conversational histories        | Participants’ email archives ranged in size from 90 MB to more than one GB, with the average size being 456 MB. The time span of these archives ranged from less than one year to over nine years of email activity.                                        | monthly and yearly words; adjusting the Time Scale; calculating the topic word(TFIDF);                                                                                                                                                                                                                       | Two modes of personalized email visualization: exploration of “big picture” trends and themes (“haystack”) and more detail-oriented exploration (“needle”).                                                                                                                                           |                                                                                                        |
| 2007* /68 Email Profiling        | Author profiling for English emails                                                      | Emails in several varieties of English, including native and non-native speakers of English coming from different geographical areas.                                                                                                                       | Analysis: document parsing , text processing and linguistic analysis. Classification using WEKA toolkit of several algorithms: decision trees RandomForest, lazy learners , rule-based learners Support Vector Machines, LibSVM  as well as ensemble/meta-learners , AdaBoostM1.                             | Results show chosen approach works well for author profiling and that using different classifiers in combination with a subset of available features can be beneficial for predicting single traits.                                                                                                  |                                                                                                        |
| 2008* /295 Sequence Labeling     | An analysis of active learning strategies for sequence labeling tasks                    | CoNLL-03 (Sang and DeMeulder, 2003) is a collection of newswire articles. NLPBA (Kim et al., 2004) is a large collection of biomedical abstracts annotated with five entities of interest. BioCreative (Yeh et al., 2005) and FlySlip (Vlachos, 2007). CORA | Sequence Labeling and CRFs; Active Learning with Sequence Models;                                                                                                                                                                                                                                            | The large-scale empirical evaluation demonstrates that some of these newly proposed methods advance the state of the art in active learning with sequence models. These methods include information density (which we recommend in practice), sequence vote entropy, and sometimes Fisher information |                                                                                                        |
| 2011* /26 Traceability           | Improving automated documentation to code traceability by combining retrieval techniques | 4 unrelated open-source systems: JDK 1.5, ArgoUML, Freenet, JMeter.                                                                                                                                                                                         | Incorporating Regular Expression (RE), Key Phrases(KP), and Clustering into a Vector Space Model (VSM) to overcoming the three main limitations of VSM. 1. RE is used to get more true links at high cut points. 2. KP tries to recover links missed by VSM. 3. Clustering is used after the first two steps | The F-Performance varies from 60% to 90% for the 4 systems.                                                                                                                                                                                                                                           |                                                                                                        |
